{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo Red CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/dramon/anaconda3/envs/dlearn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.use(\"Agg\")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "INIT_LR = 1e-3\n",
    "# its important the batch size be smaller than the total samples\n",
    "BS = 15  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "# List all the images in class folders\n",
    "list_images = list(paths.list_images(\"./Trainset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(list_images)\n",
    "# get the id class by the folder name\n",
    "labels = list(map(lambda x: x.split(\"/\")[2], list_images))\n",
    "# Load all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "claseno = {'Luffy': 0, 'NoLuffy': 1}\n",
    "codedlabels = list(map(lambda x: claseno[x], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hace lo mismo que lo que hicimos con el diccionario\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LabelEncoder().fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in list_images:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    # preprocess all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c07270438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imutils.opencv2matplotlib(data[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all the images\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "codedlabels = np.array(codedlabels)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\\\n",
    "    codedlabels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class amount and layers\n",
    "nclasses = len(np.unique(labels))\n",
    "layer_depth = data.shape[-1]\n",
    "# The categorical Y entries\n",
    "trainY = to_categorical(trainY, num_classes=nclasses)\n",
    "testY = to_categorical(testY, num_classes=nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "        horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=256, height=256, depth=layer_depth, classes=nclasses)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "# Running model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1)\n",
    "# save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] serializing network...\")\n",
    "currentTime = datetime.now().strftime(\"%S%M%H_%d%m%Y\")\n",
    "model.save(f\"./Resultados/modelo_upd_{currentTime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy QL ventana 50F1\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "#plt.savefig(f\"./Resultados/modelo_upd_{currentTime}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifica(path_image):\n",
    "    prueba = cv2.imread(path_image, cv2.IMREAD_COLOR)\n",
    "    prueba_resized = cv2.resize(prueba, (256, 256))\n",
    "    prueba_resized = prueba_resized.astype(\"float\") / 255.0\n",
    "    prueba_resized = img_to_array(prueba_resized)\n",
    "    prueba_resized2 = np.expand_dims(prueba_resized, axis=0)\n",
    "    prueba_resized.shape\n",
    "    resultado = model.predict(prueba_resized2)[0]\n",
    "    return [\"Luffy\", \"NoLuffy\"][np.argmax(resultado)]\n",
    "\n",
    "clasifica(\"/home/dramon/Pictures/ore_no_e/One Piece/calendar04_01_2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "dlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
