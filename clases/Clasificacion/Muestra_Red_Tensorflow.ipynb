{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/d5/38cd4543401708e64c9ee6afa664b936860f4630dd93a49ab863f9998cd2/tensorflow-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (63.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 63.0MB 725kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.14.3)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (39.1.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/63/f505d2d4c21db849cf80bad517f0065a30be6b006b0a5637f1b95584a305/absl-py-0.6.1.tar.gz (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 4.5MB/s a 0:00:011\n",
      "\u001b[?25hCollecting tensorboard<1.12.0,>=1.11.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.3 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.5 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.6)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.12.0,>=1.11.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 5.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /home/ramon/anaconda3/lib/python3.6/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: h5py in /home/ramon/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.5->tensorflow) (2.7.1)\n",
      "Building wheels for collected packages: termcolor, gast, absl-py\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ramon/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ramon/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ramon/.cache/pip/wheels/18/ea/5e/e36e1b8739e78cd2eba0a08fdc602c2b16a4b263912af8cb64\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: termcolor, gast, astor, absl-py, markdown, tensorboard, tensorflow\n",
      "Successfully installed absl-py-0.6.1 astor-0.7.1 gast-0.2.0 markdown-3.0.1 tensorboard-1.11.0 tensorflow-1.11.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#dataset = np.loadtxt(\"pima-indians-diabetes.data.csv\", delimiter=\",\")\n",
    "cancer = load_breast_cancer()\n",
    "tabla_cancer = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tabla_cancer.values\n",
    "Y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, input_dim=30, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "569/569 [==============================] - 0s 619us/step - loss: 0.6911 - acc: 0.6134\n",
      "Epoch 2/150\n",
      "569/569 [==============================] - 0s 28us/step - loss: 0.6868 - acc: 0.6274\n",
      "Epoch 3/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.6829 - acc: 0.6274\n",
      "Epoch 4/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.6790 - acc: 0.6274\n",
      "Epoch 5/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.6756 - acc: 0.6274\n",
      "Epoch 6/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6724 - acc: 0.6274\n",
      "Epoch 7/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.6695 - acc: 0.6274\n",
      "Epoch 8/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6674 - acc: 0.6274\n",
      "Epoch 9/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6655 - acc: 0.6274\n",
      "Epoch 10/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6639 - acc: 0.6274\n",
      "Epoch 11/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.6631 - acc: 0.6274\n",
      "Epoch 12/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6620 - acc: 0.6274\n",
      "Epoch 13/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6617 - acc: 0.6274\n",
      "Epoch 14/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.6612 - acc: 0.6274\n",
      "Epoch 15/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.6610 - acc: 0.6274\n",
      "Epoch 16/150\n",
      "569/569 [==============================] - 0s 30us/step - loss: 0.6607 - acc: 0.6274\n",
      "Epoch 17/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.6606 - acc: 0.6274\n",
      "Epoch 18/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.6605 - acc: 0.6274\n",
      "Epoch 19/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 20/150\n",
      "569/569 [==============================] - 0s 45us/step - loss: 0.6605 - acc: 0.6274\n",
      "Epoch 21/150\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.6605 - acc: 0.6274\n",
      "Epoch 22/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 23/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 24/150\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 25/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 26/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 27/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.6605 - acc: 0.6274\n",
      "Epoch 28/150\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 29/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 30/150\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 31/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 32/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 33/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.6606 - acc: 0.6274\n",
      "Epoch 34/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.6603 - acc: 0.6274\n",
      "Epoch 35/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 36/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.6605 - acc: 0.6274\n",
      "Epoch 37/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 38/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.6604 - acc: 0.6274\n",
      "Epoch 39/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.6441 - acc: 0.6274\n",
      "Epoch 40/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.6026 - acc: 0.6274\n",
      "Epoch 41/150\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.5886 - acc: 0.6274\n",
      "Epoch 42/150\n",
      "569/569 [==============================] - 0s 40us/step - loss: 0.5471 - acc: 0.6274\n",
      "Epoch 43/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.5197 - acc: 0.6274\n",
      "Epoch 44/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.4911 - acc: 0.6274\n",
      "Epoch 45/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.4669 - acc: 0.6274\n",
      "Epoch 46/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.4256 - acc: 0.6274\n",
      "Epoch 47/150\n",
      "569/569 [==============================] - 0s 29us/step - loss: 0.4025 - acc: 0.6573\n",
      "Epoch 48/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.3933 - acc: 0.9121\n",
      "Epoch 49/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.3765 - acc: 0.9227\n",
      "Epoch 50/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.3589 - acc: 0.9227\n",
      "Epoch 51/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.3445 - acc: 0.9244\n",
      "Epoch 52/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.3340 - acc: 0.9192\n",
      "Epoch 53/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.3446 - acc: 0.9209\n",
      "Epoch 54/150\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.3098 - acc: 0.9244\n",
      "Epoch 55/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.3016 - acc: 0.9209\n",
      "Epoch 56/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2900 - acc: 0.9279\n",
      "Epoch 57/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.2818 - acc: 0.9227\n",
      "Epoch 58/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.3207 - acc: 0.9139\n",
      "Epoch 59/150\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.2679 - acc: 0.9262\n",
      "Epoch 60/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2708 - acc: 0.9297\n",
      "Epoch 61/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2782 - acc: 0.9139\n",
      "Epoch 62/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.2498 - acc: 0.9244\n",
      "Epoch 63/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2607 - acc: 0.9139\n",
      "Epoch 64/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.2467 - acc: 0.9297\n",
      "Epoch 65/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2323 - acc: 0.9297\n",
      "Epoch 66/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2603 - acc: 0.9156\n",
      "Epoch 67/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2269 - acc: 0.9332\n",
      "Epoch 68/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.2474 - acc: 0.9262\n",
      "Epoch 69/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2404 - acc: 0.9192\n",
      "Epoch 70/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2177 - acc: 0.9350\n",
      "Epoch 71/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2138 - acc: 0.9244\n",
      "Epoch 72/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.2126 - acc: 0.9297\n",
      "Epoch 73/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2169 - acc: 0.9297\n",
      "Epoch 74/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2264 - acc: 0.9156\n",
      "Epoch 75/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.2061 - acc: 0.9350\n",
      "Epoch 76/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.2086 - acc: 0.9279\n",
      "Epoch 77/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2072 - acc: 0.9244\n",
      "Epoch 78/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1934 - acc: 0.9350\n",
      "Epoch 79/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.2136 - acc: 0.9315\n",
      "Epoch 80/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1936 - acc: 0.9262\n",
      "Epoch 81/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1924 - acc: 0.9315\n",
      "Epoch 82/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1917 - acc: 0.9332\n",
      "Epoch 83/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.2075 - acc: 0.9209\n",
      "Epoch 84/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1851 - acc: 0.9385\n",
      "Epoch 85/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1834 - acc: 0.9438\n",
      "Epoch 86/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1839 - acc: 0.9297\n",
      "Epoch 87/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1691 - acc: 0.9315\n",
      "Epoch 88/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1885 - acc: 0.9262\n",
      "Epoch 89/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1974 - acc: 0.9332\n",
      "Epoch 90/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.2287 - acc: 0.9174\n",
      "Epoch 91/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1961 - acc: 0.9402\n",
      "Epoch 92/150\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.1677 - acc: 0.9473\n",
      "Epoch 93/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.2130 - acc: 0.9139\n",
      "Epoch 94/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.2003 - acc: 0.9262\n",
      "Epoch 95/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1686 - acc: 0.9385\n",
      "Epoch 96/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.1601 - acc: 0.9473\n",
      "Epoch 97/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.1932 - acc: 0.9244\n",
      "Epoch 98/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.2072 - acc: 0.9156\n",
      "Epoch 99/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1723 - acc: 0.9350\n",
      "Epoch 100/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1899 - acc: 0.9227\n",
      "Epoch 101/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1618 - acc: 0.9420\n",
      "Epoch 102/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1734 - acc: 0.9332\n",
      "Epoch 103/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1531 - acc: 0.9385\n",
      "Epoch 104/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.1530 - acc: 0.9438\n",
      "Epoch 105/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1577 - acc: 0.9455\n",
      "Epoch 106/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1646 - acc: 0.9385\n",
      "Epoch 107/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1725 - acc: 0.9402\n",
      "Epoch 108/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1622 - acc: 0.9332\n",
      "Epoch 109/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1864 - acc: 0.9315\n",
      "Epoch 110/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1699 - acc: 0.9402\n",
      "Epoch 111/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1525 - acc: 0.9473\n",
      "Epoch 112/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1468 - acc: 0.9473\n",
      "Epoch 113/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1576 - acc: 0.9438\n",
      "Epoch 114/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1651 - acc: 0.9297\n",
      "Epoch 115/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1645 - acc: 0.9385\n",
      "Epoch 116/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1772 - acc: 0.9350\n",
      "Epoch 117/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1494 - acc: 0.9455\n",
      "Epoch 118/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1471 - acc: 0.9420\n",
      "Epoch 119/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1749 - acc: 0.9315\n",
      "Epoch 120/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1710 - acc: 0.9315\n",
      "Epoch 121/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1468 - acc: 0.9473\n",
      "Epoch 122/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1931 - acc: 0.9279\n",
      "Epoch 123/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1388 - acc: 0.9455\n",
      "Epoch 124/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.1490 - acc: 0.9455\n",
      "Epoch 125/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1674 - acc: 0.9332\n",
      "Epoch 126/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1445 - acc: 0.9455\n",
      "Epoch 127/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1340 - acc: 0.9508\n",
      "Epoch 128/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1284 - acc: 0.9525\n",
      "Epoch 129/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1262 - acc: 0.9490\n",
      "Epoch 130/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1349 - acc: 0.9508\n",
      "Epoch 131/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1508 - acc: 0.9385\n",
      "Epoch 132/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1448 - acc: 0.9438\n",
      "Epoch 133/150\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.2176 - acc: 0.9209\n",
      "Epoch 134/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1507 - acc: 0.9508\n",
      "Epoch 135/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1360 - acc: 0.9455\n",
      "Epoch 136/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.1401 - acc: 0.9438\n",
      "Epoch 137/150\n",
      "569/569 [==============================] - 0s 31us/step - loss: 0.1375 - acc: 0.9561\n",
      "Epoch 138/150\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.1543 - acc: 0.9350\n",
      "Epoch 139/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1443 - acc: 0.9455\n",
      "Epoch 140/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1268 - acc: 0.9508\n",
      "Epoch 141/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1361 - acc: 0.9455\n",
      "Epoch 142/150\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1202 - acc: 0.9543\n",
      "Epoch 143/150\n",
      "569/569 [==============================] - 0s 34us/step - loss: 0.1231 - acc: 0.9525\n",
      "Epoch 144/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1184 - acc: 0.9525\n",
      "Epoch 145/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1180 - acc: 0.9578\n",
      "Epoch 146/150\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1441 - acc: 0.9455\n",
      "Epoch 147/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1372 - acc: 0.9455\n",
      "Epoch 148/150\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.1731 - acc: 0.9402\n",
      "Epoch 149/150\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.1726 - acc: 0.9297\n",
      "Epoch 150/150\n",
      "569/569 [==============================] - 0s 38us/step - loss: 0.1389 - acc: 0.9490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ed4d17eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 88us/step\n",
      "\n",
      "acc: 94.38%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02566273],\n",
       "       [0.02566615],\n",
       "       [0.0256971 ],\n",
       "       [0.5371685 ],\n",
       "       [0.02690198],\n",
       "       [0.08365992],\n",
       "       [0.02570083],\n",
       "       [0.04873842],\n",
       "       [0.19136642],\n",
       "       [0.03091189],\n",
       "       [0.03142874],\n",
       "       [0.0257545 ],\n",
       "       [0.02728008],\n",
       "       [0.89610785],\n",
       "       [0.98545235],\n",
       "       [0.03747615],\n",
       "       [0.02591566],\n",
       "       [0.02573113],\n",
       "       [0.02566272],\n",
       "       [0.9935681 ],\n",
       "       [0.99514574],\n",
       "       [0.99472696],\n",
       "       [0.49299723],\n",
       "       [0.02566272],\n",
       "       [0.02566272],\n",
       "       [0.0257888 ],\n",
       "       [0.09125192],\n",
       "       [0.02708371],\n",
       "       [0.0256785 ],\n",
       "       [0.0935808 ],\n",
       "       [0.02566914],\n",
       "       [0.02580112],\n",
       "       [0.02602021],\n",
       "       [0.02566482],\n",
       "       [0.02595268],\n",
       "       [0.03111305],\n",
       "       [0.9386674 ],\n",
       "       [0.9963503 ],\n",
       "       [0.47140878],\n",
       "       [0.8807142 ],\n",
       "       [0.22228307],\n",
       "       [0.7693658 ],\n",
       "       [0.02567678],\n",
       "       [0.0278258 ],\n",
       "       [0.28798804],\n",
       "       [0.02585159],\n",
       "       [0.9929711 ],\n",
       "       [0.23156303],\n",
       "       [0.9919516 ],\n",
       "       [0.9788325 ],\n",
       "       [0.9936919 ],\n",
       "       [0.9952531 ],\n",
       "       [0.995144  ],\n",
       "       [0.03010548],\n",
       "       [0.03574858],\n",
       "       [0.99465114],\n",
       "       [0.02566272],\n",
       "       [0.03403119],\n",
       "       [0.9934151 ],\n",
       "       [0.9940404 ],\n",
       "       [0.9951337 ],\n",
       "       [0.99395156],\n",
       "       [0.03656873],\n",
       "       [0.99459237],\n",
       "       [0.02611121],\n",
       "       [0.13714421],\n",
       "       [0.99302083],\n",
       "       [0.9950557 ],\n",
       "       [0.9672954 ],\n",
       "       [0.99612963],\n",
       "       [0.02566353],\n",
       "       [0.993778  ],\n",
       "       [0.02566277],\n",
       "       [0.8096703 ],\n",
       "       [0.9878435 ],\n",
       "       [0.02769401],\n",
       "       [0.9963877 ],\n",
       "       [0.02568104],\n",
       "       [0.02585623],\n",
       "       [0.99318767],\n",
       "       [0.9771303 ],\n",
       "       [0.9944723 ],\n",
       "       [0.02566274],\n",
       "       [0.03255834],\n",
       "       [0.9894181 ],\n",
       "       [0.02573209],\n",
       "       [0.88535506],\n",
       "       [0.02570716],\n",
       "       [0.99064916],\n",
       "       [0.98383224],\n",
       "       [0.948758  ],\n",
       "       [0.96542317],\n",
       "       [0.21170163],\n",
       "       [0.9899548 ],\n",
       "       [0.06648604],\n",
       "       [0.02569048],\n",
       "       [0.9960769 ],\n",
       "       [0.99407876],\n",
       "       [0.99538606],\n",
       "       [0.90467167],\n",
       "       [0.03093869],\n",
       "       [0.98992926],\n",
       "       [0.9921177 ],\n",
       "       [0.9943897 ],\n",
       "       [0.99550253],\n",
       "       [0.05506415],\n",
       "       [0.988586  ],\n",
       "       [0.99461323],\n",
       "       [0.02566272],\n",
       "       [0.96980715],\n",
       "       [0.99492717],\n",
       "       [0.9957048 ],\n",
       "       [0.988545  ],\n",
       "       [0.99563426],\n",
       "       [0.9943435 ],\n",
       "       [0.97346175],\n",
       "       [0.99337584],\n",
       "       [0.0269359 ],\n",
       "       [0.02576753],\n",
       "       [0.04323074],\n",
       "       [0.99502546],\n",
       "       [0.02586022],\n",
       "       [0.02566295],\n",
       "       [0.99518484],\n",
       "       [0.99470526],\n",
       "       [0.9924661 ],\n",
       "       [0.03799685],\n",
       "       [0.02622678],\n",
       "       [0.9932346 ],\n",
       "       [0.02592959],\n",
       "       [0.9961265 ],\n",
       "       [0.02786508],\n",
       "       [0.03178041],\n",
       "       [0.98117596],\n",
       "       [0.02571562],\n",
       "       [0.9168907 ],\n",
       "       [0.99167717],\n",
       "       [0.9959006 ],\n",
       "       [0.05897805],\n",
       "       [0.9960283 ],\n",
       "       [0.99533963],\n",
       "       [0.02781179],\n",
       "       [0.99315053],\n",
       "       [0.9930025 ],\n",
       "       [0.99526525],\n",
       "       [0.99636614],\n",
       "       [0.92516553],\n",
       "       [0.9613148 ],\n",
       "       [0.9931223 ],\n",
       "       [0.99149466],\n",
       "       [0.99198735],\n",
       "       [0.98796624],\n",
       "       [0.9663019 ],\n",
       "       [0.99628145],\n",
       "       [0.99305713],\n",
       "       [0.9926433 ],\n",
       "       [0.02921038],\n",
       "       [0.3611387 ],\n",
       "       [0.9959027 ],\n",
       "       [0.99516124],\n",
       "       [0.9891917 ],\n",
       "       [0.0266151 ],\n",
       "       [0.02566272],\n",
       "       [0.99386144],\n",
       "       [0.02566275],\n",
       "       [0.99088216],\n",
       "       [0.9960977 ],\n",
       "       [0.029689  ],\n",
       "       [0.02566371],\n",
       "       [0.9909418 ],\n",
       "       [0.9963169 ],\n",
       "       [0.02612629],\n",
       "       [0.04830696],\n",
       "       [0.9956664 ],\n",
       "       [0.99601436],\n",
       "       [0.99328107],\n",
       "       [0.9916522 ],\n",
       "       [0.664794  ],\n",
       "       [0.99448735],\n",
       "       [0.99635905],\n",
       "       [0.02566272],\n",
       "       [0.0256628 ],\n",
       "       [0.02571009],\n",
       "       [0.9962483 ],\n",
       "       [0.09262326],\n",
       "       [0.9917596 ],\n",
       "       [0.03046199],\n",
       "       [0.9944478 ],\n",
       "       [0.9956351 ],\n",
       "       [0.9959319 ],\n",
       "       [0.55086887],\n",
       "       [0.9862651 ],\n",
       "       [0.993789  ],\n",
       "       [0.02924187],\n",
       "       [0.9860967 ],\n",
       "       [0.9954177 ],\n",
       "       [0.27567974],\n",
       "       [0.03903608],\n",
       "       [0.02571274],\n",
       "       [0.02600405],\n",
       "       [0.8760981 ],\n",
       "       [0.08001536],\n",
       "       [0.02567205],\n",
       "       [0.02566646],\n",
       "       [0.86186844],\n",
       "       [0.31794655],\n",
       "       [0.99510527],\n",
       "       [0.04461546],\n",
       "       [0.9921135 ],\n",
       "       [0.9805567 ],\n",
       "       [0.02578401],\n",
       "       [0.98977053],\n",
       "       [0.02566272],\n",
       "       [0.18224204],\n",
       "       [0.6202393 ],\n",
       "       [0.96073425],\n",
       "       [0.9925101 ],\n",
       "       [0.9940129 ],\n",
       "       [0.02566281],\n",
       "       [0.02566272],\n",
       "       [0.9948984 ],\n",
       "       [0.99550384],\n",
       "       [0.9954762 ],\n",
       "       [0.03779138],\n",
       "       [0.9858823 ],\n",
       "       [0.93197376],\n",
       "       [0.99579406],\n",
       "       [0.992829  ],\n",
       "       [0.9673848 ],\n",
       "       [0.39221865],\n",
       "       [0.09295806],\n",
       "       [0.9948277 ],\n",
       "       [0.98448193],\n",
       "       [0.02566653],\n",
       "       [0.9952779 ],\n",
       "       [0.9872364 ],\n",
       "       [0.02566272],\n",
       "       [0.02576233],\n",
       "       [0.8131705 ],\n",
       "       [0.02568997],\n",
       "       [0.9939674 ],\n",
       "       [0.99596584],\n",
       "       [0.9926479 ],\n",
       "       [0.9756369 ],\n",
       "       [0.02981191],\n",
       "       [0.9944642 ],\n",
       "       [0.9949503 ],\n",
       "       [0.99357444],\n",
       "       [0.964719  ],\n",
       "       [0.9953112 ],\n",
       "       [0.02566301],\n",
       "       [0.9948302 ],\n",
       "       [0.02566306],\n",
       "       [0.08245955],\n",
       "       [0.02566277],\n",
       "       [0.8984573 ],\n",
       "       [0.02566299],\n",
       "       [0.71074903],\n",
       "       [0.02585229],\n",
       "       [0.02849685],\n",
       "       [0.02566863],\n",
       "       [0.0488989 ],\n",
       "       [0.0285322 ],\n",
       "       [0.46701553],\n",
       "       [0.02574477],\n",
       "       [0.02566272],\n",
       "       [0.99497485],\n",
       "       [0.9884631 ],\n",
       "       [0.9948586 ],\n",
       "       [0.9951074 ],\n",
       "       [0.9958698 ],\n",
       "       [0.99622416],\n",
       "       [0.02566272],\n",
       "       [0.99528116],\n",
       "       [0.03033457],\n",
       "       [0.99462056],\n",
       "       [0.9963342 ],\n",
       "       [0.09615041],\n",
       "       [0.97846574],\n",
       "       [0.9951395 ],\n",
       "       [0.0256688 ],\n",
       "       [0.99449944],\n",
       "       [0.02585576],\n",
       "       [0.7421346 ],\n",
       "       [0.99510336],\n",
       "       [0.9954146 ],\n",
       "       [0.99268496],\n",
       "       [0.9965061 ],\n",
       "       [0.994942  ],\n",
       "       [0.99554163],\n",
       "       [0.85814714],\n",
       "       [0.98188734],\n",
       "       [0.99577063],\n",
       "       [0.99442685],\n",
       "       [0.99658775],\n",
       "       [0.9961325 ],\n",
       "       [0.99580693],\n",
       "       [0.9872388 ],\n",
       "       [0.952342  ],\n",
       "       [0.9953635 ],\n",
       "       [0.02566274],\n",
       "       [0.99453074],\n",
       "       [0.0256986 ],\n",
       "       [0.9957481 ],\n",
       "       [0.9954129 ],\n",
       "       [0.99521375],\n",
       "       [0.99551266],\n",
       "       [0.9942087 ],\n",
       "       [0.99527884],\n",
       "       [0.9941748 ],\n",
       "       [0.9954893 ],\n",
       "       [0.9805289 ],\n",
       "       [0.9955172 ],\n",
       "       [0.9964474 ],\n",
       "       [0.99215394],\n",
       "       [0.9962631 ],\n",
       "       [0.99657094],\n",
       "       [0.02631105],\n",
       "       [0.99435586],\n",
       "       [0.9956955 ],\n",
       "       [0.99561656],\n",
       "       [0.02619853],\n",
       "       [0.99563146],\n",
       "       [0.02566403],\n",
       "       [0.9938226 ],\n",
       "       [0.9958015 ],\n",
       "       [0.9941572 ],\n",
       "       [0.9956448 ],\n",
       "       [0.05495587],\n",
       "       [0.4334311 ],\n",
       "       [0.30082497],\n",
       "       [0.99369204],\n",
       "       [0.9960807 ],\n",
       "       [0.9945404 ],\n",
       "       [0.99459285],\n",
       "       [0.02595607],\n",
       "       [0.9965149 ],\n",
       "       [0.0256628 ],\n",
       "       [0.9940106 ],\n",
       "       [0.02566272],\n",
       "       [0.91604203],\n",
       "       [0.9927946 ],\n",
       "       [0.99578226],\n",
       "       [0.02637528],\n",
       "       [0.99586606],\n",
       "       [0.99535877],\n",
       "       [0.99087673],\n",
       "       [0.9798083 ],\n",
       "       [0.995574  ],\n",
       "       [0.9964051 ],\n",
       "       [0.99443287],\n",
       "       [0.726711  ],\n",
       "       [0.02566272],\n",
       "       [0.03119241],\n",
       "       [0.99613947],\n",
       "       [0.99469686],\n",
       "       [0.99470466],\n",
       "       [0.99326754],\n",
       "       [0.9942431 ],\n",
       "       [0.8332593 ],\n",
       "       [0.99479747],\n",
       "       [0.993353  ],\n",
       "       [0.9948702 ],\n",
       "       [0.778804  ],\n",
       "       [0.9940117 ],\n",
       "       [0.02573326],\n",
       "       [0.02572238],\n",
       "       [0.9454691 ],\n",
       "       [0.02566272],\n",
       "       [0.0256628 ],\n",
       "       [0.03250582],\n",
       "       [0.9944066 ],\n",
       "       [0.03396977],\n",
       "       [0.02566761],\n",
       "       [0.99563897],\n",
       "       [0.9942544 ],\n",
       "       [0.9953069 ],\n",
       "       [0.9849858 ],\n",
       "       [0.9957598 ],\n",
       "       [0.58031803],\n",
       "       [0.99538887],\n",
       "       [0.99545324],\n",
       "       [0.9961932 ],\n",
       "       [0.9889213 ],\n",
       "       [0.9961242 ],\n",
       "       [0.9316203 ],\n",
       "       [0.99591655],\n",
       "       [0.99280494],\n",
       "       [0.99589336],\n",
       "       [0.03119722],\n",
       "       [0.9959759 ],\n",
       "       [0.9936435 ],\n",
       "       [0.02566864],\n",
       "       [0.02566318],\n",
       "       [0.9932494 ],\n",
       "       [0.99481934],\n",
       "       [0.9912095 ],\n",
       "       [0.9944224 ],\n",
       "       [0.9900158 ],\n",
       "       [0.9901585 ],\n",
       "       [0.04390096],\n",
       "       [0.9899262 ],\n",
       "       [0.99421245],\n",
       "       [0.99576867],\n",
       "       [0.9960031 ],\n",
       "       [0.9934243 ],\n",
       "       [0.980824  ],\n",
       "       [0.97661984],\n",
       "       [0.03129363],\n",
       "       [0.9776833 ],\n",
       "       [0.9590483 ],\n",
       "       [0.99200684],\n",
       "       [0.9946312 ],\n",
       "       [0.8386037 ],\n",
       "       [0.13195664],\n",
       "       [0.99397403],\n",
       "       [0.98571855],\n",
       "       [0.02566273],\n",
       "       [0.9963827 ],\n",
       "       [0.99442506],\n",
       "       [0.99057055],\n",
       "       [0.98316824],\n",
       "       [0.995983  ],\n",
       "       [0.9893702 ],\n",
       "       [0.99225557],\n",
       "       [0.99379057],\n",
       "       [0.99247605],\n",
       "       [0.9402651 ],\n",
       "       [0.9961361 ],\n",
       "       [0.99541146],\n",
       "       [0.95220476],\n",
       "       [0.99636286],\n",
       "       [0.02988288],\n",
       "       [0.02570227],\n",
       "       [0.9926011 ],\n",
       "       [0.05709428],\n",
       "       [0.9935353 ],\n",
       "       [0.98880684],\n",
       "       [0.98098993],\n",
       "       [0.9953519 ],\n",
       "       [0.9906336 ],\n",
       "       [0.02708695],\n",
       "       [0.9947707 ],\n",
       "       [0.99552095],\n",
       "       [0.07433043],\n",
       "       [0.99466234],\n",
       "       [0.02581877],\n",
       "       [0.9880975 ],\n",
       "       [0.9483904 ],\n",
       "       [0.02566349],\n",
       "       [0.9940112 ],\n",
       "       [0.0284928 ],\n",
       "       [0.9911479 ],\n",
       "       [0.9947207 ],\n",
       "       [0.9861578 ],\n",
       "       [0.85535574],\n",
       "       [0.96608067],\n",
       "       [0.99098104],\n",
       "       [0.9903161 ],\n",
       "       [0.9912082 ],\n",
       "       [0.02566339],\n",
       "       [0.02566272],\n",
       "       [0.98617274],\n",
       "       [0.9946162 ],\n",
       "       [0.9822245 ],\n",
       "       [0.8748555 ],\n",
       "       [0.98200214],\n",
       "       [0.9907754 ],\n",
       "       [0.02582846],\n",
       "       [0.9917612 ],\n",
       "       [0.98793983],\n",
       "       [0.94736016],\n",
       "       [0.9406336 ],\n",
       "       [0.9714381 ],\n",
       "       [0.9954005 ],\n",
       "       [0.9949372 ],\n",
       "       [0.8810757 ],\n",
       "       [0.9940309 ],\n",
       "       [0.99591786],\n",
       "       [0.91452444],\n",
       "       [0.9940865 ],\n",
       "       [0.5940699 ],\n",
       "       [0.9950265 ],\n",
       "       [0.9935277 ],\n",
       "       [0.99496764],\n",
       "       [0.9925476 ],\n",
       "       [0.9799223 ],\n",
       "       [0.02567549],\n",
       "       [0.99332047],\n",
       "       [0.62403667],\n",
       "       [0.8736736 ],\n",
       "       [0.20280263],\n",
       "       [0.02646786],\n",
       "       [0.99636155],\n",
       "       [0.9897899 ],\n",
       "       [0.9839654 ],\n",
       "       [0.98252743],\n",
       "       [0.98908734],\n",
       "       [0.02572917],\n",
       "       [0.02575255],\n",
       "       [0.98451555],\n",
       "       [0.65938395],\n",
       "       [0.99594647],\n",
       "       [0.02566272],\n",
       "       [0.9944337 ],\n",
       "       [0.9950724 ],\n",
       "       [0.995806  ],\n",
       "       [0.9960581 ],\n",
       "       [0.9847342 ],\n",
       "       [0.46158314],\n",
       "       [0.9964144 ],\n",
       "       [0.9945861 ],\n",
       "       [0.04974683],\n",
       "       [0.97900546],\n",
       "       [0.2343593 ],\n",
       "       [0.9944056 ],\n",
       "       [0.02618738],\n",
       "       [0.02615565],\n",
       "       [0.9787119 ],\n",
       "       [0.99428374],\n",
       "       [0.9951137 ],\n",
       "       [0.02566272],\n",
       "       [0.9959925 ],\n",
       "       [0.9898421 ],\n",
       "       [0.9939175 ],\n",
       "       [0.9941531 ],\n",
       "       [0.9591081 ],\n",
       "       [0.99508506],\n",
       "       [0.9941706 ],\n",
       "       [0.99584204],\n",
       "       [0.9904642 ],\n",
       "       [0.95320356],\n",
       "       [0.9406698 ],\n",
       "       [0.02588199],\n",
       "       [0.9960051 ],\n",
       "       [0.02570028],\n",
       "       [0.98372674],\n",
       "       [0.99419725],\n",
       "       [0.9791003 ],\n",
       "       [0.9734196 ],\n",
       "       [0.99631965],\n",
       "       [0.9452566 ],\n",
       "       [0.9138202 ],\n",
       "       [0.990531  ],\n",
       "       [0.9931878 ],\n",
       "       [0.9698823 ],\n",
       "       [0.9956404 ],\n",
       "       [0.9955254 ],\n",
       "       [0.99275124],\n",
       "       [0.9373434 ],\n",
       "       [0.9959929 ],\n",
       "       [0.99533796],\n",
       "       [0.9910329 ],\n",
       "       [0.9942842 ],\n",
       "       [0.99130917],\n",
       "       [0.99493164],\n",
       "       [0.9952891 ],\n",
       "       [0.9921233 ],\n",
       "       [0.99200773],\n",
       "       [0.99232966],\n",
       "       [0.97635525],\n",
       "       [0.993404  ],\n",
       "       [0.18285912],\n",
       "       [0.02568379],\n",
       "       [0.02566346],\n",
       "       [0.02567722],\n",
       "       [0.04590685],\n",
       "       [0.02566736],\n",
       "       [0.94868344]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(predictions.reshape(-1,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
